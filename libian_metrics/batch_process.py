"""
Batch processing module for analyzing character glyphs in organized folder structures.

This module provides functionality to process multiple characters, each with multiple
glyph images, and compute average metrics for each character.

Module: libian_metrics.batch_process
Author: LiShift Team
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple
import numpy as np
from .io_utils import read_image
from .preprocess import preprocess
from .metrics import compute_all_metrics

logger = logging.getLogger(__name__)


def process_character_folder(
    char_folder: str,
    char_name: str,
    calib: Dict = None
) -> Tuple[Dict, List[str]]:
    """
    Process all images in a character folder and compute average metrics.
    
    å¤„ç†å•ä¸ªå­—çš„æ‰€æœ‰å›¾ç‰‡ï¼Œå¹¶è®¡ç®—å¹³å‡æŒ‡æ ‡ã€‚
    
    Args:
        char_folder (str): Path to folder containing images of a single character.
                          å•å­—æ–‡ä»¶å¤¹è·¯å¾„
        char_name (str): Name of the character (e.g., "ä¹™", "ç”²").
                        å­—çš„åç§°
        calib (dict): Calibration parameters. If None, use defaults.
                     æ ¡å‡†å‚æ•°ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
    
    Returns:
        tuple: (averaged_metrics_dict, list_of_image_paths)
               (å¹³å‡æŒ‡æ ‡å­—å…¸, å¤„ç†çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨)
    
    Example:
        >>> metrics, images = process_character_folder("data/dataset/ä¹™", "ä¹™")
        >>> print(f"Character ä¹™ LQI: {metrics['LQI']:.2f}")
    """
    if calib is None:
        calib = {}
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    
    # æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = []
    if os.path.isdir(char_folder):
        for file in os.listdir(char_folder):
            if os.path.splitext(file)[1].lower() in supported_formats:
                image_files.append(os.path.join(char_folder, file))
    
    if not image_files:
        logger.warning(f"No images found in {char_folder}")
        return None, []
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    all_metrics = []
    processed_images = []
    
    for img_path in sorted(image_files):
        try:
            img = read_image(img_path)
            if img is None:
                logger.warning(f"Failed to read image: {img_path}")
                continue
            
            bin_img, skel, meta = preprocess(img)
            metrics = compute_all_metrics(bin_img, skel, calib)
            all_metrics.append(metrics)
            processed_images.append(img_path)
            
            logger.info(f"âœ“ Processed: {os.path.basename(img_path)} "
                       f"(LQI={metrics['LQI']:.3f})")
        except Exception as e:
            logger.error(f"Error processing {img_path}: {e}")
            continue
    
    if not all_metrics:
        logger.warning(f"No metrics computed for character {char_name}")
        return None, []
    
    # è®¡ç®—å¹³å‡å€¼
    avg_metrics = {}
    metric_keys = all_metrics[0].keys()
    
    for key in metric_keys:
        values = [m[key] for m in all_metrics if isinstance(m[key], (int, float))]
        if values:
            avg_metrics[key] = float(np.mean(values))
            avg_metrics[f"{key}_std"] = float(np.std(values))
    
    avg_metrics['char'] = char_name
    avg_metrics['image_count'] = len(processed_images)
    
    return avg_metrics, processed_images


def process_dataset_folder(
    dataset_folder: str,
    calib: Dict = None,
    output_json: str = None
) -> Dict:
    """
    Process entire dataset folder with organized character subfolders.
    
    å¤„ç†æ•´ä¸ªæ•°æ®é›†æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«å¤šä¸ªå­—çš„å­æ–‡ä»¶å¤¹ã€‚
    
    Args:
        dataset_folder (str): Path to dataset folder structure:
                            æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œç»“æ„ä¸ºï¼š
                            
                            dataset_folder/
                            â”œâ”€â”€ å­—1/
                            â”‚   â”œâ”€â”€ image1.jpg
                            â”‚   â””â”€â”€ image2.jpg
                            â”œâ”€â”€ å­—2/
                            â”‚   â””â”€â”€ ...
                            â””â”€â”€ ...
        
        calib (dict): Calibration parameters. If None, use defaults.
                     æ ¡å‡†å‚æ•°
        
        output_json (str): Path to save results JSON. If None, don't save.
                          è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: Results dictionary with structure:
             ç»“æœå­—å…¸ï¼Œç»“æ„ä¸ºï¼š
             {
                 "dataset_name": "folder_name",
                 "timestamp": "2024-01-06T23:30:00",
                 "characters": {
                     "å­—1": {
                         "SSI": 0.71,
                         "SSI_std": 0.05,
                         ...
                         "image_count": 5
                     },
                     ...
                 },
                 "summary": {
                     "total_characters": 10,
                     "total_images": 45,
                     "average_LQI": 0.65
                 }
             }
    
    Example:
        >>> results = process_dataset_folder("data/oracle_bones")
        >>> print(f"Processed {results['summary']['total_characters']} characters")
    """
    if calib is None:
        calib = {}
    
    dataset_folder = os.path.abspath(dataset_folder)
    dataset_name = os.path.basename(dataset_folder)
    
    if not os.path.isdir(dataset_folder):
        raise ValueError(f"Dataset folder not found: {dataset_folder}")
    
    logger.info(f"Processing dataset: {dataset_name}")
    logger.info(f"Dataset path: {dataset_folder}")
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ Dataset: {dataset_name}")
    print(f"{'='*60}\n")
    
    # æ”¶é›†å­—æ–‡ä»¶å¤¹
    char_folders = []
    for item in os.listdir(dataset_folder):
        item_path = os.path.join(dataset_folder, item)
        if os.path.isdir(item_path) and not item.startswith('.'):
            char_folders.append((item, item_path))
    
    char_folders.sort()
    
    if not char_folders:
        raise ValueError(f"No character folders found in {dataset_folder}")
    
    # å¤„ç†æ¯ä¸ªå­—
    results = {
        'dataset_name': dataset_name,
        'dataset_path': dataset_folder,
        'timestamp': __import__('datetime').datetime.now().isoformat(),
        'characters': {}
    }
    
    total_images = 0
    lqi_scores = []
    
    for char_name, char_folder in char_folders:
        print(f"Processing character: {char_name}")
        avg_metrics, image_paths = process_character_folder(
            char_folder, char_name, calib
        )
        
        if avg_metrics:
            results['characters'][char_name] = avg_metrics
            total_images += len(image_paths)
            if 'LQI' in avg_metrics:
                lqi_scores.append(avg_metrics['LQI'])
            
            print(f"  âœ“ {char_name}: LQI={avg_metrics['LQI']:.3f} "
                  f"({len(image_paths)} images)")
        else:
            print(f"  âœ— {char_name}: No valid images")
        print()
    
    # æ±‡æ€»ç»Ÿè®¡
    results['summary'] = {
        'total_characters': len([c for c in results['characters'] if results['characters'][c]]),
        'total_images': total_images,
        'average_LQI': float(np.mean(lqi_scores)) if lqi_scores else None,
        'lqi_min': float(np.min(lqi_scores)) if lqi_scores else None,
        'lqi_max': float(np.max(lqi_scores)) if lqi_scores else None,
    }
    
    # ä¿å­˜ç»“æœ
    if output_json:
        output_json = os.path.abspath(output_json)
        os.makedirs(os.path.dirname(output_json), exist_ok=True)
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logger.info(f"Results saved to: {output_json}")
        print(f"âœ… Results saved to: {output_json}")
    
    return results


def print_results(results: Dict, detailed: bool = False) -> None:
    """
    Print results in a formatted table.
    
    ä»¥è¡¨æ ¼æ ¼å¼æ‰“å°ç»“æœã€‚
    
    Args:
        results (dict): Results dictionary from process_dataset_folder
        detailed (bool): If True, show detailed metrics for each character
                        å¦‚æœä¸ºTrueï¼Œæ˜¾ç¤ºæ¯ä¸ªå­—çš„è¯¦ç»†æŒ‡æ ‡
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“Š Dataset: {results['dataset_name']}")
    print(f"{'='*70}")
    
    summary = results.get('summary', {})
    print(f"\nğŸ“ˆ Summary:")
    print(f"  Total Characters: {summary.get('total_characters', 0)}")
    print(f"  Total Images: {summary.get('total_images', 0)}")
    print(f"  Average LQI: {summary.get('average_LQI', 0):.3f}")
    print(f"  LQI Range: {summary.get('lqi_min', 0):.3f} - {summary.get('lqi_max', 0):.3f}")
    
    if detailed:
        print(f"\n{'='*70}")
        print(f"{'Character':<10} {'LQI':<8} {'SSI':<8} {'GCP':<8} {'SSD':<8} "
              f"{'STR':<8} {'CSI':<8} {'COI':<8} {'Count':<8}")
        print(f"{'-'*70}")
        
        for char_name, metrics in sorted(results['characters'].items()):
            if metrics:
                print(f"{char_name:<10} "
                      f"{metrics.get('LQI', 0):<8.3f} "
                      f"{metrics.get('SSI', 0):<8.3f} "
                      f"{metrics.get('GCP', 0):<8.3f} "
                      f"{metrics.get('SSD', 0):<8.3f} "
                      f"{metrics.get('STR', 0):<8.3f} "
                      f"{metrics.get('CSI', 0):<8.3f} "
                      f"{metrics.get('COI', 0):<8.3f} "
                      f"{metrics.get('image_count', 0):<8}")
    
    print(f"\n{'='*70}\n")
